{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from skimage import io, transform\n",
    "from tensorflow.python.framework import graph_util\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/'\n",
    "w = 24\n",
    "h = 24\n",
    "c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    cate   = [path + x for x in os.listdir(path) if os.path.isdir(path + x)]\n",
    "    imgs   = []\n",
    "    labels = []\n",
    "    for idx, folder in enumerate(cate):\n",
    "        for im in glob.glob(folder + '/*.jpg'):\n",
    "            print('reading the image: %s' % (im))\n",
    "            img = io.imread(im)\n",
    "            img = transform.resize(img, (w, h, c))\n",
    "            imgs.append(img)\n",
    "            labels.append(idx)\n",
    "    return np.asarray(imgs, np.float32), np.asarray(labels, np.int32)\n",
    "data, label = read_img(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_example = data.shape[0]\n",
    "arr = np.arange(num_example)\n",
    "np.random.shuffle(arr)\n",
    "data = data[arr]\n",
    "label = label[arr]\n",
    "\n",
    "ratio = 0.8\n",
    "s = np.int(num_example * ratio)\n",
    "x_train = data[:s]\n",
    "y_train = label[:s]\n",
    "x_val   = data[s:]\n",
    "y_val   = label[s:]\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(height, width, channel):\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, height, width, channel], name='input')\n",
    "    y = tf.placeholder(tf.int64, shape=[None, 2], name='labels_placeholder')\n",
    "\n",
    "    def weight_variable(shape, name=\"weights\"):\n",
    "        initial = tf.truncated_normal(shape, dtype=tf.float32, stddev=0.1)\n",
    "        return tf.Variable(initial, name=name)\n",
    "\n",
    "    def bias_variable(shape, name=\"biases\"):\n",
    "        initial = tf.constant(0.1, dtype=tf.float32, shape=shape)\n",
    "        return tf.Variable(initial, name=name)\n",
    "\n",
    "    def conv2d(input, w):\n",
    "        return tf.nn.conv2d(input, w, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    def pool_max(input):\n",
    "        return tf.nn.max_pool(input,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "\n",
    "    def fc(input, w, b):\n",
    "        return tf.matmul(input, w) + b\n",
    "\n",
    "    # conv1\n",
    "    with tf.name_scope('conv1_1') as scope:\n",
    "        kernel = weight_variable([3, 3, 3, 64])\n",
    "        biases = bias_variable([64])\n",
    "        output_conv1_1 = tf.nn.relu(conv2d(x, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv1_2') as scope:\n",
    "        kernel = weight_variable([3, 3, 64, 64])\n",
    "        biases = bias_variable([64])\n",
    "        output_conv1_2 = tf.nn.relu(conv2d(output_conv1_1, kernel) + biases, name=scope)\n",
    "\n",
    "    pool1 = pool_max(output_conv1_2)\n",
    "\n",
    "    # conv2\n",
    "    with tf.name_scope('conv2_1') as scope:\n",
    "        kernel = weight_variable([3, 3, 64, 128])\n",
    "        biases = bias_variable([128])\n",
    "        output_conv2_1 = tf.nn.relu(conv2d(pool1, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv2_2') as scope:\n",
    "        kernel = weight_variable([3, 3, 128, 128])\n",
    "        biases = bias_variable([128])\n",
    "        output_conv2_2 = tf.nn.relu(conv2d(output_conv2_1, kernel) + biases, name=scope)\n",
    "\n",
    "    pool2 = pool_max(output_conv2_2)\n",
    "\n",
    "    # conv3\n",
    "    with tf.name_scope('conv3_1') as scope:\n",
    "        kernel = weight_variable([3, 3, 128, 256])\n",
    "        biases = bias_variable([256])\n",
    "        output_conv3_1 = tf.nn.relu(conv2d(pool2, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv3_2') as scope:\n",
    "        kernel = weight_variable([3, 3, 256, 256])\n",
    "        biases = bias_variable([256])\n",
    "        output_conv3_2 = tf.nn.relu(conv2d(output_conv3_1, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv3_3') as scope:\n",
    "        kernel = weight_variable([3, 3, 256, 256])\n",
    "        biases = bias_variable([256])\n",
    "        output_conv3_3 = tf.nn.relu(conv2d(output_conv3_2, kernel) + biases, name=scope)\n",
    "\n",
    "    pool3 = pool_max(output_conv3_3)\n",
    "\n",
    "    # conv4\n",
    "    with tf.name_scope('conv4_1') as scope:\n",
    "        kernel = weight_variable([3, 3, 256, 512])\n",
    "        biases = bias_variable([512])\n",
    "        output_conv4_1 = tf.nn.relu(conv2d(pool3, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv4_2') as scope:\n",
    "        kernel = weight_variable([3, 3, 512, 512])\n",
    "        biases = bias_variable([512])\n",
    "        output_conv4_2 = tf.nn.relu(conv2d(output_conv4_1, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv4_3') as scope:\n",
    "        kernel = weight_variable([3, 3, 512, 512])\n",
    "        biases = bias_variable([512])\n",
    "        output_conv4_3 = tf.nn.relu(conv2d(output_conv4_2, kernel) + biases, name=scope)\n",
    "\n",
    "    pool4 = pool_max(output_conv4_3)\n",
    "\n",
    "    # conv5\n",
    "    with tf.name_scope('conv5_1') as scope:\n",
    "        kernel = weight_variable([3, 3, 512, 512])\n",
    "        biases = bias_variable([512])\n",
    "        output_conv5_1 = tf.nn.relu(conv2d(pool4, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv5_2') as scope:\n",
    "        kernel = weight_variable([3, 3, 512, 512])\n",
    "        biases = bias_variable([512])\n",
    "        output_conv5_2 = tf.nn.relu(conv2d(output_conv5_1, kernel) + biases, name=scope)\n",
    "\n",
    "    with tf.name_scope('conv5_3') as scope:\n",
    "        kernel = weight_variable([3, 3, 512, 512])\n",
    "        biases = bias_variable([512])\n",
    "        output_conv5_3 = tf.nn.relu(conv2d(output_conv5_2, kernel) + biases, name=scope)\n",
    "\n",
    "    pool5 = pool_max(output_conv5_3)\n",
    "\n",
    "    #fc6\n",
    "    with tf.name_scope('fc6') as scope:\n",
    "        shape = int(np.prod(pool5.get_shape()[1:]))\n",
    "        kernel = weight_variable([shape, 4096])\n",
    "        biases = bias_variable([4096])\n",
    "        pool5_flat = tf.reshape(pool5, [-1, shape])\n",
    "        output_fc6 = tf.nn.relu(fc(pool5_flat, kernel, biases), name=scope)\n",
    "\n",
    "    #fc7\n",
    "    with tf.name_scope('fc7') as scope:\n",
    "        kernel = weight_variable([4096, 4096])\n",
    "        biases = bias_variable([4096])\n",
    "        output_fc7 = tf.nn.relu(fc(output_fc6, kernel, biases), name=scope)\n",
    "\n",
    "    #fc8\n",
    "    with tf.name_scope('fc8') as scope:\n",
    "        kernel = weight_variable([4096, 2])\n",
    "        biases = bias_variable([2])\n",
    "        output_fc8 = tf.nn.relu(fc(output_fc7, kernel, biases), name=scope)\n",
    "\n",
    "    finaloutput = tf.nn.softmax(output_fc8, name=\"softmax\")\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=finaloutput, labels=y))\n",
    "    optimize = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "    prediction_labels = tf.argmax(finaloutput, axis=1, name=\"output\")\n",
    "    read_labels = y\n",
    "\n",
    "    correct_prediction = tf.equal(prediction_labels, read_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    correct_times_in_batch = tf.reduce_sum(tf.cast(correct_prediction, tf.int32))\n",
    "\n",
    "    return dict(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        optimize=optimize,\n",
    "        correct_prediction=correct_prediction,\n",
    "        correct_times_in_batch=correct_times_in_batch,\n",
    "        cost=cost,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node fc6_1/weights/Adam/Assign (defined at <ipython-input-11-742c751ae037>:130) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'fc6_1/weights/Adam/Assign':\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-e09e788075b9>\", line 69, in <module>\n    main()\n  File \"<ipython-input-12-e09e788075b9>\", line 66, in main\n    g = build_network(height=224, width=224, channel=3)\n  File \"<ipython-input-11-742c751ae037>\", line 130, in build_network\n    optimize = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 413, in minimize\n    name=name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 597, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 1156, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 197, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 171, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 73, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1572, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1315, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 568, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 520, in _true_getter\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 938, in _get_single_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 2612, in default_variable_creator\n    shape=shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 1684, in __init__\n    shape=shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 1862, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1351\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1352\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1444\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1445\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node fc6_1/weights/Adam/Assign}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e09e788075b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpb_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-e09e788075b9>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpb_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-e09e788075b9>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(graph, batch_size, num_epochs, pb_file_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mepoch_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 960\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    961\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1183\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1184\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1361\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1384\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1386\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node fc6_1/weights/Adam/Assign (defined at <ipython-input-11-742c751ae037>:130) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'fc6_1/weights/Adam/Assign':\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-e09e788075b9>\", line 69, in <module>\n    main()\n  File \"<ipython-input-12-e09e788075b9>\", line 66, in main\n    g = build_network(height=224, width=224, channel=3)\n  File \"<ipython-input-11-742c751ae037>\", line 130, in build_network\n    optimize = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 413, in minimize\n    name=name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 597, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 1156, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 197, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 171, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 73, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1572, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1315, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 568, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 520, in _true_getter\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 938, in _get_single_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 2612, in default_variable_creator\n    shape=shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 1684, in __init__\n    shape=shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 1862, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Glau\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "def train_network(graph, batch_size, num_epochs, pb_file_path):\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        epoch_delta = 2\n",
    "        for epoch_index in range(num_epochs):\n",
    "            for i in range(12):\n",
    "                sess.run([graph['optimize']], feed_dict={\n",
    "                    graph['x']: np.reshape(x_train[i], (1, 224, 224, 3)),\n",
    "                    graph['y']: ([[1, 0]] if y_train[i] == 0 else [[0, 1]])\n",
    "                })\n",
    "            if epoch_index % epoch_delta == 0:\n",
    "                total_batches_in_train_set = 0\n",
    "                total_correct_times_in_train_set = 0\n",
    "                total_cost_in_train_set = 0.\n",
    "                for i in range(12):\n",
    "                    return_correct_times_in_batch = sess.run(graph['correct_times_in_batch'], feed_dict={\n",
    "                        graph['x']: np.reshape(x_train[i], (1, 224, 224, 3)),\n",
    "                        graph['y']: ([[1, 0]] if y_train[i] == 0 else [[0, 1]])\n",
    "                    })\n",
    "                    mean_cost_in_batch = sess.run(graph['cost'], feed_dict={\n",
    "                        graph['x']: np.reshape(x_train[i], (1, 224, 224, 3)),\n",
    "                        graph['y']: ([[1, 0]] if y_train[i] == 0 else [[0, 1]])\n",
    "                    })\n",
    "                    total_batches_in_train_set += 1\n",
    "                    total_correct_times_in_train_set += return_correct_times_in_batch\n",
    "                    total_cost_in_train_set += (mean_cost_in_batch * batch_size)\n",
    "\n",
    "\n",
    "                total_batches_in_test_set = 0\n",
    "                total_correct_times_in_test_set = 0\n",
    "                total_cost_in_test_set = 0.\n",
    "                for i in range(3):\n",
    "                    return_correct_times_in_batch = sess.run(graph['correct_times_in_batch'], feed_dict={\n",
    "                        graph['x']: np.reshape(x_val[i], (1, 224, 224, 3)),\n",
    "                        graph['y']: ([[1, 0]] if y_val[i] == 0 else [[0, 1]])\n",
    "                    })\n",
    "                    mean_cost_in_batch = sess.run(graph['cost'], feed_dict={\n",
    "                        graph['x']: np.reshape(x_val[i], (1, 224, 224, 3)),\n",
    "                        graph['y']: ([[1, 0]] if y_val[i] == 0 else [[0, 1]])\n",
    "                    })\n",
    "                    total_batches_in_test_set += 1\n",
    "                    total_correct_times_in_test_set += return_correct_times_in_batch\n",
    "                    total_cost_in_test_set += (mean_cost_in_batch * batch_size)\n",
    "\n",
    "                acy_on_test  = total_correct_times_in_test_set / float(total_batches_in_test_set * batch_size)\n",
    "                acy_on_train = total_correct_times_in_train_set / float(total_batches_in_train_set * batch_size)\n",
    "                print('Epoch - {:2d}, acy_on_test:{:6.2f}%({}/{}),loss_on_test:{:6.2f}, acy_on_train:{:6.2f}%({}/{}),loss_on_train:{:6.2f}'.format(epoch_index, acy_on_test*100.0,total_correct_times_in_test_set,\n",
    "                                                                                                                                                   total_batches_in_test_set * batch_size,\n",
    "                                                                                                                                                   total_cost_in_test_set,\n",
    "                                                                                                                                                   acy_on_train * 100.0,\n",
    "                                                                                                                                                   total_correct_times_in_train_set,\n",
    "                                                                                                                                                   total_batches_in_train_set * batch_size,\n",
    "                                                                                                                                                   total_cost_in_train_set))\n",
    "            constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, [\"output\"])\n",
    "            with tf.gfile.FastGFile(pb_file_path, mode='wb') as f:\n",
    "                f.write(constant_graph.SerializeToString())\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 12\n",
    "    num_epochs = 50\n",
    "\n",
    "    pb_file_path = \"vggs.pb\"\n",
    "\n",
    "    g = build_network(height=224, width=224, channel=3)\n",
    "    train_network(g, batch_size, num_epochs, pb_file_path)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
