{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "#import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "PATH = pathlib.Path('C:\\\\Users\\\\Glau\\\\Desktop\\\\DP\\\\temp\\\\')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'Train')\n",
    "validation_dir = os.path.join(PATH, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BAS_dir = os.path.join(train_dir, 'BAS')  \n",
    "train_EBO_dir = os.path.join(train_dir, 'EBO')  \n",
    "train_EOS_dir = os.path.join(train_dir, 'EOS')  \n",
    "train_KSC_dir = os.path.join(train_dir, 'KSC')  \n",
    "validation_BAS_dir = os.path.join(validation_dir, 'BAS')  \n",
    "validation_EBO_dir = os.path.join(validation_dir, 'EBO')  \n",
    "validation_EOS_dir = os.path.join(validation_dir, 'EOS')  \n",
    "validation_KSC_dir = os.path.join(validation_dir, 'KSC')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "epochs = 100\n",
    "IMG_HEIGHT = 400\n",
    "IMG_WIDTH = 400\n",
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:173: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28809 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size = batch_size, directory = train_dir, shuffle = True, \n",
    "                                                           target_size = (IMG_HEIGHT, IMG_WIDTH), class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7191 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = train_image_generator.flow_from_directory(batch_size = batch_size, directory = validation_dir, shuffle = True, \n",
    "                                                           target_size = (IMG_HEIGHT, IMG_WIDTH), class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data, labels = next(np.array(train_data_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_data_gen.classes),train_data_gen.classes)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Clean and simple Keras implementation of network architectures described in:\n",
    "\n",
    "\n",
    "    - (ResNet-50) [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf).\n",
    "\n",
    "\n",
    "    - (ResNeXt-50 32x4d) [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/pdf/1611.05431.pdf).\n",
    "\n",
    "\n",
    "Python 3.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "#\n",
    "# image dimensions\n",
    "#\n",
    "img_height = 400\n",
    "img_width = 400\n",
    "img_channels = 3\n",
    "#\n",
    "# network params\n",
    "#\n",
    "cardinality = 32\n",
    "d = 4  # bottleneck width\n",
    "def residual_network(x, architecture='ResNet'):\n",
    "\n",
    "    if architecture.lower() == 'resnet':\n",
    "\n",
    "        channel_scale_factor = 2\n",
    "\n",
    "        grouped = False\n",
    "\n",
    "    elif architecture.lower() == 'resnext':\n",
    "\n",
    "        channel_scale_factor = 1\n",
    "\n",
    "        grouped = True\n",
    "\n",
    "    else:\n",
    "        assert False, 'Invalid architecture specified. Must be one of { \\'ResNet\\', \\'ResNeXt\\' }.'\n",
    "    def add_common_layers(y):\n",
    "\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        y = layers.LeakyReLU()(y)\n",
    "        return y\n",
    "\n",
    "    def grouped_convolution(y, nb_channels, _strides):\n",
    "\n",
    "        assert not nb_channels % cardinality\n",
    "\n",
    "        _d = nb_channels // cardinality\n",
    "\n",
    "        # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "        # and convolutions are separately performed within each group\n",
    "        groups = []\n",
    "        for j in range(cardinality):\n",
    "            group = layers.Lambda(lambda z: z[:, :, :, j * _d:j * _d + _d])(y)\n",
    "            groups.append(layers.Conv2D(_d, kernel_size=(3, 3), strides=_strides, padding='same')(group))\n",
    "        # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "        y = layers.concatenate(groups)\n",
    "        return y\n",
    "    def residual_block(y, nb_channels_in, nb_channels_out, _strides=(1, 1), _project_shortcut=False, _grouped=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "        and are subject to two simple rules:\n",
    "        - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "        - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "        \"\"\"\n",
    "        shortcut = y\n",
    "\n",
    "      # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "\n",
    "        y = layers.Conv2D(nb_channels_in, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "\n",
    "        y = add_common_layers(y)\n",
    "        if not _grouped:\n",
    "            # ResNet\n",
    "            y = layers.Conv2D(nb_channels_in, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "        else:\n",
    "            # ResNeXt\n",
    "            y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        y = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "       # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "        if _project_shortcut or _strides != (1, 1):\n",
    "            # when the dimensions increase projection shortcut is used to match dimensions (done by 1Ã—1 convolutions\n",
    "\n",
    "            # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "            shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "        y = layers.add([shortcut, y])\n",
    "\n",
    "        # relu is performed right after each batch normalization\n",
    "\n",
    "        # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "\n",
    "        y = layers.LeakyReLU()(y)\n",
    "\n",
    "        return y\n",
    "    # conv1\n",
    "    x = layers.Conv2D(16, kernel_size=(7, 7), strides=(2, 2), padding='same')(x)\n",
    "    x = add_common_layers(x)\n",
    "  # conv2\n",
    "    x = layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    for i in range(3):\n",
    "        project_shortcut = True if i == 0 else False\n",
    "        x = residual_block(x, 32 // channel_scale_factor, 64, _project_shortcut=project_shortcut, _grouped=grouped)\n",
    "    # conv3\n",
    "    for i in range(4):\n",
    "        # down-sampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 128 // channel_scale_factor, 256, _strides=strides, _grouped=grouped)\n",
    "    # conv4\n",
    "    for i in range(6):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 256 // channel_scale_factor, 1024, _strides=strides, _grouped=grouped)\n",
    "    # conv5\n",
    "    for i in range(3):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 1024 // channel_scale_factor, 2048, _strides=strides, _grouped=grouped)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(15)(x)\n",
    "    return x\n",
    "image_tensor = layers.Input(shape=(img_height, img_width, img_channels))\n",
    "network_output = residual_network(image_tensor, architecture='ResNeXt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = models.Model(inputs=[image_tensor], outputs=[network_output])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
