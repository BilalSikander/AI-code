{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\glau\\.conda\\envs\\tensorflow\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: image-classifiers==1.0.0b1 in c:\\users\\glau\\.conda\\envs\\tensorflow\\lib\\site-packages (1.0.0b1)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "!pip install image-classifiers==1.0.0b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard,TerminateOnNaN, LearningRateScheduler\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from tensorflow.keras.layers import Lambda, Reshape, DepthwiseConv2D, ZeroPadding2D, Add, MaxPooling2D,Activation, Flatten, Conv2D, Dense, Input, Dropout, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from datetime import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'C:\\Users\\Glau\\Desktop\\test\\covid-chestxray-dataset-master'\n",
    "log_path = './logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-74d8f729c3bc>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-74d8f729c3bc>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    rm -rf dataset\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf dataset\n",
    "mkdir -p dataset/covid\n",
    "#mkdir -p dataset/normal\n",
    "#mkdir -p dataset/pneumonia\n",
    "mkdir -p logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('../input/covid-chest-xray/images/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid xray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_dataset_path = r'C:\\Users\\Glau\\Desktop\\test\\covid-chestxray-dataset-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the path to the metadata CSV file and load it\n",
    "csvPath = os.path.sep.join([covid_dataset_path, \"metadata.csv\"])\n",
    "df = pd.read_csv(csvPath)\n",
    "\n",
    "# loop over the rows of the COVID-19 data frame\n",
    "for (i, row) in df.iterrows():\n",
    "    # if (1) the current case is not COVID-19 or (2) this is not\n",
    "    # a 'PA' view, then ignore the row\n",
    "    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n",
    "        continue\n",
    "\n",
    "    # build the path to the input image file\n",
    "    imagePath = os.path.sep.join([covid_dataset_path, \"images\", row[\"filename\"]])\n",
    "\n",
    "    # if the input image file does not exist (there are some errors in\n",
    "    # the COVID-19 metadeta file), ignore the row\n",
    "    if not os.path.exists(imagePath):\n",
    "        continue\n",
    "\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = row[\"filename\"].split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([f\"{dataset_path}/covid\", filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build normal xray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_dataset_path ='../input/chest-xray-pneumonia/chest_xray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"NORMAL\"])\n",
    "imagePaths = list(paths.list_images(basePath))\n",
    "\n",
    "# randomly sample the image paths\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:samples]\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = imagePath.split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"PNEUMONIA\"])\n",
    "imagePaths = list(paths.list_images(basePath))\n",
    "\n",
    "# randomly sample the image paths\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:samples]\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = imagePath.split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([f\"{dataset_path}/pneumonia\", filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot x-rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('../working/dataset/normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('../working/dataset/pneumonia/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to plot the images in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceildiv(a, b):\n",
    "    return -(-a // b)\n",
    "\n",
    "def plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n",
    "    \"\"\"Plot the images in a grid\"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    if maintitle is not None: plt.suptitle(maintitle, fontsize=10)\n",
    "    for i in range(len(imspaths)):\n",
    "        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        img = plt.imread(imspaths[i])\n",
    "        plt.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images = list(paths.list_images(f\"{dataset_path}/normal\"))\n",
    "covid_images = list(paths.list_images(f\"{dataset_path}/covid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_from_files(normal_images, rows=5, maintitle=\"Normal X-ray images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_from_files(covid_images, rows=5, maintitle=\"Covid-19 X-ray images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label_map = {'pneumonia' : 2, 'covid' : 1, 'normal' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(dataset_path))\n",
    "data = []\n",
    "labels = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(class_to_label_map[label])\n",
    "# convert the data and labels to NumPy arrays while scaling the pixel\n",
    "# intensities to the range [0, 1]\n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "# perform one-hot encoding on the labels\n",
    "#labels = to_categorical(labels)\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.15, stratify=labels, random_state=42)\n",
    "# initialize the training data augmentation object\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                   rotation_range=60,\n",
    "                                   horizontal_flip = True ,\n",
    "                                   vertical_flip = True ,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainYSparse = trainY\n",
    "trainY = to_categorical(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "N_FOLDS = 8\n",
    "EPOCHS =100\n",
    "INIT_LR = 3e-4\n",
    "T_BS = 16\n",
    "V_BS = 16\n",
    "decay_rate = 0.95\n",
    "decay_step = 1\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, random_state=1234,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "#\n",
    "# image dimensions\n",
    "#\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_channels = 3\n",
    "\n",
    "#\n",
    "# network params\n",
    "#\n",
    "\n",
    "cardinality = 32\n",
    "\n",
    "\n",
    "def residual_network(x):\n",
    "    \"\"\"\n",
    "    ResNeXt by default. For ResNet set `cardinality` = 1 above.\n",
    "    \n",
    "    \"\"\"\n",
    "    def add_common_layers(y):\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        y = layers.ReLU()(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def grouped_convolution(y, nb_channels, _strides):\n",
    "        # when `cardinality` == 1 this is just a standard convolution\n",
    "        if cardinality == 1:\n",
    "            return layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "        \n",
    "        assert not nb_channels % cardinality\n",
    "        _d = nb_channels // cardinality\n",
    "\n",
    "        # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "        # and convolutions are separately performed within each group\n",
    "        groups = []\n",
    "        for j in range(cardinality):\n",
    "            group = layers.Lambda(lambda z: z[:, :, :, j * _d:j * _d + _d])(y)\n",
    "            groups.append(layers.Conv2D(_d, kernel_size=(3, 3), strides=_strides, padding='same')(group))\n",
    "            \n",
    "        # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "        y = layers.concatenate(groups)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def residual_block(y, nb_channels_in, nb_channels_out, _strides=(1, 1), _project_shortcut=False):\n",
    "        \"\"\"\n",
    "        Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "        and are subject to two simple rules:\n",
    "\n",
    "        - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "        - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "        \"\"\"\n",
    "        shortcut = y\n",
    "\n",
    "        # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "        y = layers.Conv2D(nb_channels_in, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        # ResNeXt (identical to ResNet when `cardinality` == 1)\n",
    "        y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        y = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "        if _project_shortcut or _strides != (1, 1):\n",
    "            # when the dimensions increase projection shortcut is used to match dimensions (done by 1Ã—1 convolutions)\n",
    "            # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "            shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        y = layers.add([shortcut, y])\n",
    "\n",
    "        # relu is performed right after each batch normalization,\n",
    "        # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "        y = layers.LeakyReLU()(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    # conv1\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(x)\n",
    "    x = add_common_layers(x)\n",
    "\n",
    "    # conv2\n",
    "    x = layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    for i in range(3):\n",
    "        project_shortcut = True if i == 0 else False\n",
    "        x = residual_block(x, 128, 256, _project_shortcut=project_shortcut)\n",
    "\n",
    "    # conv3\n",
    "    for i in range(4):\n",
    "        # down-sampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 256, 512, _strides=strides)\n",
    "\n",
    "    # conv4\n",
    "    for i in range(6):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 512, 1024, _strides=strides)\n",
    "\n",
    "    # conv5\n",
    "    for i in range(3):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 1024, 2048, _strides=strides)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(3,activation='softmax')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "image_tensor = layers.Input(shape=(img_height, img_width, img_channels))\n",
    "network_output = residual_network(image_tensor)\n",
    "  \n",
    "model = models.Model(inputs=[image_tensor], outputs=[network_output])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=INIT_LR),\n",
    "                  metrics=['acc', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, skf_splits in zip(range(0,N_FOLDS),skf.split(trainX,trainYSparse)):\n",
    "\n",
    "    train_idx = skf_splits[0]\n",
    "    val_idx = skf_splits[1]\n",
    "    history = model.fit(\n",
    "                train_datagen.flow(trainX[train_idx], trainY[train_idx], batch_size=T_BS),\n",
    "                steps_per_epoch=len(train_idx) // T_BS,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data = val_datagen.flow(trainX[val_idx], trainY[val_idx], batch_size=V_BS),\n",
    "                validation_steps = len(val_idx) // V_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_predictions = []\n",
    "\n",
    "preds = model.predict(testX, batch_size=V_BS)\n",
    "submission_predictions.append(preds)\n",
    "print(submission_predictions)\n",
    "#print(f\"Test Accuracy: {submission_predictions[1]*100}\")\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='valid')\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"number of epochs\")\n",
    "plt.legend([\"train\", \"valid\"], loc=\"upper left\")\n",
    "plt.savefig('loss_performance'+'_'+str(epoch)+'.png')\n",
    "plt.clf()\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='valid')\n",
    "plt.title(\"model acc\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"number of epochs\")\n",
    "plt.legend([\"train\", \"valid\"], loc=\"upper left\")\n",
    "plt.savefig('acc_performance'+'_'+str(epoch)+'.png')    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "\tdef __init__(self, model, classIdx, layerName=None):\n",
    "\t\t# store the model, the class index used to measure the class\n",
    "\t\t# activation map, and the layer to be used when visualizing\n",
    "\t\t# the class activation map\n",
    "\t\tself.model = model\n",
    "\t\tself.classIdx = classIdx\n",
    "\t\tself.layerName = layerName\n",
    "\n",
    "\t\t# if the layer name is None, attempt to automatically find\n",
    "\t\t# the target output layer\n",
    "\t\tif self.layerName is None:\n",
    "\t\t\tself.layerName = self.find_target_layer()\n",
    "\n",
    "\tdef find_target_layer(self):\n",
    "\t\t# attempt to find the final convolutional layer in the network\n",
    "\t\t# by looping over the layers of the network in reverse order\n",
    "\t\tfor layer in reversed(self.model.layers):\n",
    "\t\t\t# check to see if the layer has a 4D output\n",
    "\t\t\tif len(layer.output_shape) == 4:\n",
    "\t\t\t\treturn layer.name\n",
    "\n",
    "\t\t# otherwise, we could not find a 4D layer so the GradCAM\n",
    "\t\t# algorithm cannot be applied\n",
    "\t\traise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
    "\n",
    "\tdef compute_heatmap(self, image, eps=1e-8):\n",
    "\t\t# construct our gradient model by supplying (1) the inputs\n",
    "\t\t# to our pre-trained model, (2) the output of the (presumably)\n",
    "\t\t# final 4D layer in the network, and (3) the output of the\n",
    "\t\t# softmax activations from the model\n",
    "\t\tgradModel = Model(\n",
    "\t\t\tinputs=[self.model.inputs],\n",
    "\t\t\toutputs=[self.model.get_layer(self.layerName).output, \n",
    "                     \n",
    "\t\t\t\tself.model.output])\n",
    "\n",
    "\t\t# record operations for automatic differentiation\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\t# cast the image tensor to a float-32 data type, pass the\n",
    "\t\t\t# image through the gradient model, and grab the loss\n",
    "\t\t\t# associated with the specific class index\n",
    "\t\t\tinputs = tf.cast(image, tf.float32)\n",
    "\t\t\t(convOutputs, predictions) = gradModel(inputs)\n",
    "\t\t\tloss = predictions[:, self.classIdx]\n",
    "\n",
    "\t\t# use automatic differentiation to compute the gradients\n",
    "\t\tgrads = tape.gradient(loss, convOutputs)\n",
    "\n",
    "\t\t# compute the guided gradients\n",
    "\t\tcastConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "\t\tcastGrads = tf.cast(grads > 0, \"float32\")\n",
    "\t\tguidedGrads = castConvOutputs * castGrads * grads\n",
    "\n",
    "\t\t# the convolution and guided gradients have a batch dimension\n",
    "\t\t# (which we don't need) so let's grab the volume itself and\n",
    "\t\t# discard the batch\n",
    "\t\tconvOutputs = convOutputs[0]\n",
    "\t\tguidedGrads = guidedGrads[0]\n",
    "\n",
    "\t\t# compute the average of the gradient values, and using them\n",
    "\t\t# as weights, compute the ponderation of the filters with\n",
    "\t\t# respect to the weights\n",
    "\t\tweights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "\t\tcam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "\n",
    "\t\t# grab the spatial dimensions of the input image and resize\n",
    "\t\t# the output class activation map to match the input image\n",
    "\t\t# dimensions\n",
    "\t\t(w, h) = (image.shape[2], image.shape[1])\n",
    "\t\theatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "\n",
    "\t\t# normalize the heatmap such that all values lie in the range\n",
    "\t\t# [0, 1], scale the resulting values to the range [0, 255],\n",
    "\t\t# and then convert to an unsigned 8-bit integer\n",
    "\t\tnumer = heatmap - np.min(heatmap)\n",
    "\t\tdenom = (heatmap.max() - heatmap.min()) + eps\n",
    "\t\theatmap = numer / denom\n",
    "\t\theatmap = (heatmap * 255).astype(\"uint8\")\n",
    "\n",
    "\t\t# return the resulting heatmap to the calling function\n",
    "\t\treturn heatmap\n",
    "\n",
    "\tdef overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
    "\t\tcolormap=cv2.COLORMAP_JET):\n",
    "\t\t# apply the supplied color map to the heatmap and then\n",
    "\t\t# overlay the heatmap on the input image\n",
    "\t\theatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "\t\toutput = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "\n",
    "\t\t# return a 2-tuple of the color mapped heatmap and the output,\n",
    "\t\t# overlaid image\n",
    "\t\treturn (heatmap, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(testY == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid1 = testX[50]\n",
    "covid2 = testX[4]\n",
    "covid3 = testX[35]\n",
    "covid_list = [covid1, covid2, covid3]\n",
    "pneumonia1 = testX[2]\n",
    "pneumonia2 = testX[43]\n",
    "pneumonia3 = testX[52]\n",
    "pneumonia_list = [pneumonia1, pneumonia2, pneumonia3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = testX[7]\n",
    "preds = model.predict(image[np.newaxis,...])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = model.predict(image[np.newaxis,...])\n",
    "i = np.argmax(preds[0])\n",
    "\n",
    "# decode the ImageNet predictions to obtain the human-readable label\n",
    "\n",
    "# # initialize our gradient class activation map and build the heatmap\n",
    "cam = GradCAM(model, i)\n",
    "heatmap = cam.compute_heatmap(image[np.newaxis,...])\n",
    "\n",
    "img_copy = np.copy(image)\n",
    "img_copy -= img_copy.min((0,1))\n",
    "img_copy = (255*img_copy).astype(np.uint8)\n",
    "# resize the resulting heatmap to the original input image dimensions\n",
    "# and then overlay heatmap on top of the image\n",
    "heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "(heatmap, output) = cam.overlay_heatmap(heatmap, img_copy, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(img_list):\n",
    "    fig, axes = plt.subplots(len(img_list), 2, figsize=(15, 15))\n",
    "    fig.suptitle('Pneumonia Grad-CAM\\n',fontsize=20)\n",
    "    \n",
    "    for i, img in enumerate(img_list):\n",
    "        preds = model.predict(img[np.newaxis,...])\n",
    "        axes[i,0].imshow(img, cmap = 'bone')\n",
    "        axes[i,0].set_xticks([])\n",
    "        axes[i,0].set_yticks([])\n",
    "      #  axes[i,0].set_title(f'{class_label[np.argmax(preds[:, 1:]) + 1]} / {class_label[np.argmax(label[:, 1:]) + 1]} / {np.max(preds[:, 1:]):.4f}')\n",
    "        heatmap = cam.compute_heatmap(img[np.newaxis,...])\n",
    "        img_copy = np.copy(img)\n",
    "        img_copy -= img_copy.min((0,1))\n",
    "        img_copy = (255*img_copy).astype(np.uint8)\n",
    "        # resize the resulting heatmap to the original input image dimensions\n",
    "        # and then overlay heatmap on top of the image\n",
    "        heatmap = cv2.resize(heatmap, (img_copy.shape[1], img_copy.shape[0]))\n",
    "        (heatmap, output) = cam.overlay_heatmap(heatmap, img_copy, alpha=0.5)\n",
    "        axes[i,1].imshow(output)\n",
    "        axes[i,1].set_xticks([])\n",
    "        axes[i,1].set_yticks([])\n",
    "        #axes[i,1].set_title(\"heatmap showing hemorrhage location\")\n",
    "    plt.subplots_adjust(wspace=1, hspace=0.2)\n",
    "    plt.savefig('CovidGradCAM.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(covid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(pneumonia_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = np.average(submission_predictions, axis = 0, weights = [2**i for i in range(len(submission_predictions))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(testY, predY, multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(testY, predY, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label_map = {2 : 'pneumonia', 1 : 'covid', 0 : 'normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_multiclass_roc(y_test, y_score, n_classes, figsize=(17, 6)):\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], class_to_label_map[i]))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "plot_multiclass_roc(testY, predY, n_classes=3, figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_mat = confusion_matrix(testY, np.argmax(predY, axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize = 'xx-large')\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(cm_mat, \n",
    "                      normalize = False,\n",
    "                      target_names = ['normal', 'covid', 'pneumonia'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testY, np.argmax(predY, axis = -1), target_names = ['normal', 'covid', 'pneumonia']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf dataset\n",
    "!rm -rf logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
